import streamlit as st
import pandas as pd
import requests
from sqlalchemy import create_engine
from ydata_profiling import ProfileReport
from streamlit.components.v1 import html

# Configuration globale
st.set_page_config(page_title="DataStack - Data Engineering App", layout="wide")

# === Fonctionnalit√©s G√©n√©rales ===

def load_local_file(file, delimiter):
    """Charger un fichier local (CSV, Excel, etc.) avec un d√©limiteur d√©fini."""
    try:
        if file.name.endswith(".csv"):
            return pd.read_csv(file, delimiter=delimiter)
        elif file.name.endswith(".xlsx"):
            return pd.read_excel(file)
        else:
            st.error("Type de fichier non support√©. Veuillez utiliser un fichier CSV ou Excel.")
            return None
    except Exception as e:
        st.error(f"Erreur lors du chargement du fichier : {e}")
        return None

def load_from_database(connection_string, query):
    """Charger des donn√©es √† partir d'une base de donn√©es via SQLAlchemy."""
    try:
        engine = create_engine(connection_string)
        with engine.connect() as conn:
            return pd.read_sql(query, conn)
    except Exception as e:
        st.error(f"Erreur de connexion √† la base de donn√©es : {e}")
        return None

def load_from_api(api_url, headers, params):
    """Charger des donn√©es depuis une API."""
    try:
        response = requests.get(api_url, headers=headers, params=params)
        response.raise_for_status()  # L√®ve une exception pour les erreurs HTTP
        data = response.json()  # D√©coder la r√©ponse JSON
        if isinstance(data, list):
            return pd.DataFrame(data)
        elif isinstance(data, dict) and 'data' in data:
            return pd.DataFrame(data['data'])
        else:
            st.error("Format des donn√©es API non support√©. Attendu : liste ou dictionnaire avec cl√© 'data'.")
            return None
    except Exception as e:
        st.error(f"Erreur lors de la connexion √† l'API : {e}")
        return None

def clean_data(df):
    """Nettoyer les donn√©es (exemple simplifi√©)."""
    df = df.dropna()  # Supprime les valeurs manquantes
    df = df.drop_duplicates()  # Supprime les doublons
    return df

def explore_data(df):
    """Effectuer une EDA simple."""
    st.write("**R√©sum√© statistique**")
    st.write(df.describe())

def generate_profile_report(df):
    """G√©n√©rer un rapport de profilage interactif."""
    profile = ProfileReport(df, title="Rapport EDA", explorative=True)
    profile.to_file("eda_report.html")
    with open("eda_report.html", "r", encoding="utf-8") as f:
        report_html = f.read()
    html(report_html, height=1000, scrolling=True)

# === Interface Utilisateur ===
st.title("üõ†Ô∏è DataStack - Plateforme de Data Engineering")

# 1. S√©lection de la source de donn√©es
st.sidebar.header("1Ô∏è‚É£ Charger les donn√©es")
source_type = st.sidebar.radio(
    "Choisissez la source de donn√©es",
    options=["Fichier local", "Base de donn√©es", "API"]
)

data = None

if source_type == "Fichier local":
    uploaded_file = st.sidebar.file_uploader("T√©l√©versez votre fichier", type=["csv", "xlsx"])
    delimiter = st.sidebar.text_input("D√©limiteur (par d√©faut : ',')", value=";")
    if uploaded_file is not None:
        data = load_local_file(uploaded_file, delimiter)

elif source_type == "Base de donn√©es":
    db_connection = st.sidebar.text_input("Cha√Æne de connexion (SQLAlchemy)", "")
    db_query = st.sidebar.text_area("Requ√™te SQL", "SELECT * FROM your_table")
    if st.sidebar.button("Charger depuis la base de donn√©es"):
        data = load_from_database(db_connection, db_query)

elif source_type == "API":
    api_url = st.sidebar.text_input("URL de l'API", "https://api.example.com/data")
    headers_input = st.sidebar.text_area("En-t√™tes (format JSON)", '{"Authorization": "Bearer YOUR_TOKEN"}')
    params_input = st.sidebar.text_area("Param√®tres (format JSON)", '{"key1": "value1", "key2": "value2"}')

    # Convertir les entr√©es texte en dictionnaires
    headers = {}
    params = {}
    try:
        if headers_input:
            headers = eval(headers_input)  # Convertir la cha√Æne JSON en dictionnaire
        if params_input:
            params = eval(params_input)
    except Exception as e:
        st.error(f"Erreur dans le format des en-t√™tes ou des param√®tres : {e}")

    if st.sidebar.button("Charger depuis l'API"):
        data = load_from_api(api_url, headers, params)

# 2. Nettoyage et exploration
if data is not None:
    st.sidebar.header("2Ô∏è‚É£ Traiter les donn√©es")
    action = st.sidebar.selectbox(
        "Choisissez une action",
        options=["Aper√ßu des donn√©es", "Nettoyer les donn√©es", "EDA (Exploration des Donn√©es)"]
    )
    
    if action == "Aper√ßu des donn√©es":
        st.subheader("üîç Aper√ßu des donn√©es")
        st.dataframe(data.head())  # Afficher un aper√ßu unique ici
    elif action == "Nettoyer les donn√©es":
        st.subheader("üßπ Nettoyage des donn√©es")
        cleaned_data = clean_data(data)
        st.dataframe(cleaned_data)
        st.download_button("T√©l√©charger les donn√©es nettoy√©es", data=cleaned_data.to_csv(index=False), file_name="cleaned_data.csv")
    elif action == "EDA (Exploration des Donn√©es)":
        st.subheader("üìä Exploration des Donn√©es")
        st.sidebar.info("Un peu de patience .")
        if st.sidebar.button("G√©n√©rer un rapport de profilage interactif"):
            with st.spinner("G√©n√©ration du rapport..."):
                generate_profile_report(data)

# 3. Construction de pipeline ETL
st.sidebar.header("3Ô∏è‚É£ Pipeline ETL")
if data is not None:
    etl_step = st.sidebar.multiselect(
        "√âtapes du pipeline ETL",
        options=["Extraction", "Transformation", "Chargement"]
    )
    
    if st.sidebar.button("Ex√©cuter le Pipeline ETL"):
        st.subheader("‚öôÔ∏è Pipeline ETL")
        st.write(f"√âtapes s√©lectionn√©es : {etl_step}")
        if "Extraction" in etl_step:
            st.write("‚úîÔ∏è Donn√©es extraites.")
        if "Transformation" in etl_step:
            transformed_data = clean_data(data)
            st.write("‚úîÔ∏è Donn√©es transform√©es.")
            st.dataframe(transformed_data.head())
        if "Chargement" in etl_step:
            st.write("‚úîÔ∏è Donn√©es charg√©es dans la destination (non impl√©ment√©).")


st.sidebar.info("Notre Application est √©volutive - Les modules seront ajout√©s au fur et a mesure pour enrichir cette plateforme.")